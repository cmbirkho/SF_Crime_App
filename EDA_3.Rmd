---
title: "EDA_ML"
author: "Connor Birkhold"
date: "2/12/2020"
output: html_document
---
### **Multiclass Text Classification**
#### **Use machine learning to predict the incident_category using the language filled out in the incident_description**

#### The Process
1. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.width = 8, fig.height = 5)
```

```{r include=FALSE}
rm(list = ls())

library(data.table)
library(tidyverse)
library(lubridate)
library(RSQLite)
library(DBI)
library(caret)

library(stopwords)
library(tm)
```


```{r}
dbPath <- "C:/Users/Cbirkho/Documents/SF_Crime_App/SF_Application/sf_crime_db.sqlite"

db <- dbConnect(SQLite(), dbname = dbPath)

df <- dbGetQuery(db,  "SELECT *
                       FROM incident_reports;")

dbDisconnect(db)

setDT(df)
```

#### **How many incident categories are there and what are there frequencies?**
```{r}
df <- df[, c("incident_id_nbr_cd",
             "incident_description",
             "incident_category")]

df$cnt <- 1


ggplot(df, aes(incident_category, cnt)) +
    geom_bar(stat = 'identity') +
    theme(axis.text.x = element_text(angle = 45, h = 1))

```

#### **Remove Incident Categories with less than 3 incident**
```{r}
filt <- df[, .(sum = sum(cnt)),
           by = incident_category] %>% 
    .[sum >= 3,]

df <- df[incident_category %in% filt$incident_category, ]
```

```{r}
set.seed(54321)
indexes <- createDataPartition(df$incident_category,
                               times = 1,
                               p = 0.7,
                               list = FALSE)

training <- df[indexes,]
testing <- df[- indexes,]
```

#### **Make a Corpus**
```{r}
# rename
training <- df %>% rename(doc_id = incident_id_nbr_cd,
                      text = incident_description)

testing <- df %>% rename(doc_id = incident_id_nbr_cd,
                      text = incident_description)
# data frame source
trainSource <- DataframeSource(training)

testSource <- DataframeSource(testing)
# create corpus
trainCorpus <- VCorpus(trainSource)

testCorpus <- VCorpus(testSource)
```

#### **Text Cleaning**
* all lowercase
* no punctuation marks
* remove numbers
* remove stop words
* clean white space
```{r}
clean.Text <- function(corpus){
    
    corpus <- tm_map(corpus, content_transformer(removePunctuation))
    corpus <- tm_map(corpus, content_transformer(tolower))
    corpus <- tm_map(corpus, removeNumbers)
    corpus <- tm_map(corpus, content_transformer(removeWords), stopwords("english"))
    # corpus <- tm_map(corpus, stemDocument)
    corpus <- tm_map(corpus, stripWhitespace)
    
    return(corpus)
}

trainCorpus <- clean.Text(trainCorpus)

testCorpus <- clean.Text(testCorpus)

```


#### **Converting Text to Features**
* bag of words 
```{r}

word.Bag <- function(corpus, data){
    
    docMatrix <- DocumentTermMatrix(corpus)
    dfMatrix <- as.matrix(docMatrix)
    dfMatrix <- cbind(dfMatrix, data$incident_category)
    colnames(dfMatrix)[ncol(dfMatrix)] <- "incident_category"
    dfNew <- as.data.frame(dfMatrix)
    
    return(dfNew)
}

trainNew <- word.Bag(trainCorpus, training)

testNew <- word.Bag(testCorpus, testing)

```


```{r}
train.control <- trainControl(method = "repeatedcv",
                              number = 10,
                              repeats = 3,
                              search = "grid")

caret.cv <- train(incident_category ~ .,
                  data = trainNew,
                  trControl = train.control,
                  method = "rf")
```

#### **Results**
* Either the model is overfit (most incidents are "Larceny Theft") or incident descriptions are a very reliable source of classifying the category which makes sense
```{r}
pred <- predict(caret.cv, testNew)

confusionMatrix(testNew$incident_category, pred)$overall
```

