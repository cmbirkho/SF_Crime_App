---
title: "EDA_ML"
author: "Connor Birkhold"
date: "2/12/2020"
output: html_document
---
### **Multiclass Text Classification**
#### **Use machine learning to predict the incident_category using just the language filled out in the incident_description**

#### The Process
1. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.width = 8, fig.height = 5)
```

```{r include=FALSE}
rm(list = ls())

library(data.table)
library(tidyverse)
library(lubridate)
library(RSQLite)
library(DBI)
library(caret)

library(stopwords)
library(tm)
library(lexicon)
```


```{r}
dbPath <- "C:/Users/Cbirkho/Documents/SF_Crime_App/SF_Application/sf_crime_db.sqlite"

db <- dbConnect(SQLite(), dbname = dbPath)

df <- dbGetQuery(db,  "SELECT *
                       FROM incident_reports;")

dbDisconnect(db)

setDT(df)
```

#### **How many incident categories are there and what are there frequencies?**
```{r}
df <- df[, c("incident_id_nbr_cd",
             "incident_description",
             "incident_category")]

df$cnt <- 1


ggplot(df, aes(incident_category, cnt)) +
    geom_bar(stat = 'identity') +
    theme(axis.text.x = element_text(angle = 45, h = 1))

```

#### **Remove Incident Categories with only 1 incident**
```{r}
filt <- df[, .(sum = sum(cnt)),
           by = incident_category] %>% 
    .[sum <= 1,]

"%ni%" <- Negate("%in%")

df <- df[incident_category %ni% filt$incident_category, ]
```


#### **Make a Corpus**
```{r}
# make a corpus
test <- df %>% rename(doc_id = incident_id_nbr_cd,
                      text = incident_description)

dfSource <- DataframeSource(test)

dfCorpus <- VCorpus(dfSource)
```

#### **Text Cleaning**
* all lowercase
* no punctuation marks
* remove numbers
* remove stop words
* clean white space
```{r}
clean.Text <- function(corpus){
    
    corpus <- tm_map(corpus, content_transformer(removePunctuation))
    corpus <- tm_map(corpus, content_transformer(tolower))
    corpus <- tm_map(corpus, removeNumbers)
    corpus <- tm_map(corpus, content_transformer(removeWords), stopwords("english"))
    # corpus <- tm_map(corpus, stemDocument)
    corpus <- tm_map(corpus, stripWhitespace)
    
    return(corpus)
}

dfCorpus <- clean.Text(dfCorpus)

```


#### **Converting Text to Features**
* bag of words 
```{r}

word.Bag <- function(corpus, data){
    
    docMatrix <- DocumentTermMatrix(corpus)
    dfMatrix <- as.matrix(docMatrix)
    dfMatrix <- cbind(dfMatrix, data$incident_category)
    colnames(dfMatrix)[ncol(dfMatrix)] <- "incident_category"
    dfNew <- as.data.frame(dfMatrix)
    
    return(dfNew)
}

dfNew <- word.Bag(dfCorpus, df)


```

```{r}
set.seed(54321)
indexes <- createDataPartition(dfNew$incident_category,
                               times = 1,
                               p = 0.7,
                               list = FALSE)

training <- dfNew[indexes,]
testing <- dfNew[- indexes,]
```

```{r}
train.control <- trainControl(method = "repeatedcv",
                              number = 10,
                              repeats = 3,
                              search = "grid")

caret.cv <- train(incident_category ~ .,
                  data = training,
                  method = "rf",
                  trControl = train.control)
```

```{r}
pred <- predict(caret.cv, testing)

confusionMatrix(testing$incident_category, pred)
```

